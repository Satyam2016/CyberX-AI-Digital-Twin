# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K1Pi65tHEMrdMr7WDZqB34qD4k5fpdzU
"""

!pip install imbalanced-learn xgboost

from google.colab import files
uploaded = files.upload()

from google.colab import drive
drive.mount('/content/drive')

# Update the file path accordingly
file_path = "/content/drive/MyDrive/Data_66_featurs.csv"

# Install necessary packages
# !pip install imbalanced-learn xgboost

# Import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, accuracy_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.inspection import permutation_importance
from imblearn.over_sampling import SMOTE
import random


# Update with your dataset's path
# file_path = "./Data_66_featurs.csv"  # Ensure the filename matches

# Step 1: Load Dataset
data = pd.read_csv(file_path)

# Step 2: Preprocessing
# Handle missing or infinite values
data = data.fillna(data.mean())
data = data.replace([float("inf"), float("-inf")], 0)

# Separate features and labels
X = data.drop("Label", axis=1)  # Replace "Label" if it's named differently in your dataset
y = data["Label"]

# Step 2.1: Balancing the dataset using SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Step 3: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.2, random_state=42
)

# Step 4: Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 5: Define Models and Hyperparameter Tuning
models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42)
}

# Hyperparameter tuning for Random Forest and Gradient Boosting
param_grid_rf = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5],
}

param_grid_gb = {
    'n_estimators': [100, 200],
    'learning_rate': [0.01, 0.1],
    'max_depth': [3, 5, 7]
}

# Best model performance
best_model = None
best_score = 0
best_f1 = 0

results = []

# Step 6: Train Models and Evaluate
for model_name, model in models.items():
    # Hyperparameter Tuning using GridSearchCV
    if model_name == "Random Forest":
        grid_search = GridSearchCV(model, param_grid_rf, cv=3, n_jobs=-1, verbose=1)
        grid_search.fit(X_train_scaled, y_train)
        model = grid_search.best_estimator_
    elif model_name == "Gradient Boosting":
        grid_search = GridSearchCV(model, param_grid_gb, cv=3, n_jobs=-1, verbose=1)
        grid_search.fit(X_train_scaled, y_train)
        model = grid_search.best_estimator_

    # For XGBoost, you might also want to include hyperparameter tuning
    # Currently, it's using default parameters

    # Train model
    model.fit(X_train_scaled, y_train)

    # Predict
    y_pred = model.predict(X_test_scaled)

    # Evaluate performance
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')  # Specify average if multiclass
    results.append((model_name, acc, f1))

    # Print classification report
    print(f"Results for {model_name}:")
    print("Accuracy:", acc)
    print("F1 Score:", f1)
    print("Classification Report:\n", classification_report(y_test, y_pred))
    print("-" * 40)

    # Store best model based on F1 score
    if f1 > best_f1:
        best_f1 = f1
        best_model = model

# Step 7: Feature Importance and Pattern Generation Enhancement
print(f"Best Model: {best_model}")
if isinstance(best_model, (RandomForestClassifier, GradientBoostingClassifier, XGBClassifier)):
    importances = best_model.feature_importances_
    importance_df = pd.DataFrame({
        "Feature": X.columns,
        "Importance": importances
    }).sort_values(by="Importance", ascending=False)
    print("Top Features contributing to the XSS patterns:")
    print(importance_df.head(10))

    # Step 8: Simulate New XSS Attack Patterns
    def generate_simulated_patterns(importance_df):
        top_features = importance_df["Feature"].head(5).tolist()
        print("\nTop 5 Features contributing to the attack patterns:")
        print(top_features)
        simulated_attacks = []

        # Example attack patterns based on important features
        if "url_tag_script" in top_features:
            simulated_attacks.append("<script>alert('Simulated XSS');</script>")
        if "html_tag_img" in top_features:
            simulated_attacks.append("<img src=x onerror=alert('Simulated XSS')>")
        if "js_method_eval" in top_features:
            simulated_attacks.append("eval('alert(\"Simulated XSS\")')")
        if "html_event_onload" in top_features:
            simulated_attacks.append("<div onload=alert('Simulated XSS')>Test</div>")
        if "js_method_alert" in top_features:
            simulated_attacks.append("alert('Simulated XSS')")

        print("\nGenerated Simulated XSS Patterns:")
        for attack in simulated_attacks:
            print(attack)

    generate_simulated_patterns(importance_df)